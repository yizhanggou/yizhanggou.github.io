---
title: "20180319监督学习"
author: 一张狗
lastmod: 2019-07-06 11:11:58
date: 2018-03-20 10:32:18
tags: []
---

## 一、监督学习算法

1. 监督学习：样本标注上标签，从已知标签的数据（训练集）中学习出规律。主要由分类和回归两大算法。回归是预测一个连续的数值。分类是离散的。算法：SVM、决策树、神经网络、LR等
2. 非监督学习：样本无标签，从样本集中发现规律算法：kmeans、lda、word2vec等
3. 业界主要使用监督学习算法，研究和应用都是最广泛的，效果也非常好

监督学习算法流程：

现实生活中比较多的工作在与数据集、定义问题、寻找预料。
![48edf2750afb0535c1ef866a5a9db39e](http://yizhanggou.top/imgs/2019/07/48edf2750afb0535c1ef866a5a9db39e.png)

例子：

1. 定义问题
情感极性分析，分析出文章、句子的情感极性。
2. 寻找语料
寻找数据集：爬虫、众标注；
3. 特征工程
如何表示样本

    3.1. 抽取信息
比如一幅图片的信息：
毛发：黄
眼镜：2

![82954f98565e175ad00928beecdd5976](http://yizhanggou.top/imgs/2019/07/82954f98565e175ad00928beecdd5976.png)

特征需要具有区分性。

还需要消除噪音。

    3.2 如何表示？

连续特征：（取值为实数域）
腿长度:0.5 毛长度:0.3 眼睛个数:2

二元特征：（取值为True/False）
吐舌头:0 四个腿:1
离散特征：（取值为有限集，枚举变量）

    - 毛颜色:黄 (不是数值)
    - 毛颜色: [1, 0, 0, 0] (黄色)
    - 毛颜色: [1, 0, 1, 0] (又黄又蓝)
    
one-hot表示法

![](http://yizhanggou.top/wp-content/uploads/2018/03/77346f2c7725299dd365c193e97f20bb.png)

    3.3 如何表示句子？

        1.搜集数据集。

![5853a422fe051ca2e46be26237f35b68](http://yizhanggou.top/imgs/2019/07/5853a422fe051ca2e46be26237f35b68.png)

        2.切词。

jieba、nlpc
今天/好/开心 好/高兴 不/开心

        3.句子转换成向量（N-gram模型
切词:今天好 开心 高兴 不
uni-gram表示：label就是正向、负向。

![409de4eecd1711cfc0995264e052fb25](http://yizhanggou.top/imgs/2019/07/409de4eecd1711cfc0995264e052fb25.png)

        4.bi-gram
uni-gram存在局限，考虑两句子的表示:我不开心 VS 不， 我开心

这里如果用uni-gram表示，则表示出来的向量是一样的。所以我们需要引入上下文相关，即引入两两词合并的特征，即bi-gram模型；注意，
稀疏、高维、模型处理更困难;最多到达5-gram。

![4beab71a983ea67313551c0c6d3af196](http://yizhanggou.top/imgs/2019/07/4beab71a983ea67313551c0c6d3af196.png)

        5. 模型效果 = 特征(如何表示样本) + 模型(如何从样本中学习规律)

真实的数据挖掘场景下，大部分的精力是在特征工程，即如何更好地表示样本

深度学习：自动构建特征，无需人工定义

        6. 除了直观的特征，还可以加入人工特征。

例如:TF-IDF、Topic特征、语义特征等
手工定义、统计、挖掘、模型输出等

![54dfafa1c834cff30d517947edb268ac](http://yizhanggou.top/imgs/2019/07/54dfafa1c834cff30d517947edb268ac.png)


## 二、模型建立（logistic regression）

1. 线性回归模型

线性回归模型：利用直线来拟合历史数据![](http://yizhanggou.top/wp-content/uploads/2018/03/38ec1af8d1cd2e16cb1de7bbf9a18868.png)

2.线性模型预测句子分类

![4800f7289214c343aec3559732d6c3f2](http://yizhanggou.top/imgs/2019/07/4800f7289214c343aec3559732d6c3f2.png)
![fb6dfd42a61b90ecd7c703812476fcbe](http://yizhanggou.top/imgs/2019/07/fb6dfd42a61b90ecd7c703812476fcbe.png)

3.如何得到句子的正向/负向的概率?
通过映射函数，映射到概率值
这里hw(x)指的是Sigmoid函数。因为值域与我们的y值一样，所以这里选用Sigmoid函数。
![b0b4f7e09d3041e3a1d699a2ccf2ffed](http://yizhanggou.top/imgs/2019/07/b0b4f7e09d3041e3a1d699a2ccf2ffed.png)

Sigmoid函数：
(0，1)取值范围，符合概率定义
处处光滑、二阶可导，其导数为：

![1c8ffc9432226f747bd2f78bd68aada1](http://yizhanggou.top/imgs/2019/07/1c8ffc9432226f747bd2f78bd68aada1.png)

4.最大似然目标函数

    4.1 似然函数是一种关于统计模型中的参数的函数，表示模型参数中的似然性；

最大似然估计是样本的函数。

样本是由概率分布D抽样产生，通过样本构造似然函数，再推测概率分布D的参数。

        - 构造似然函数 
        - 求解似然函数

    4.2 观察到三个句子样本，由相互独立概率公式，似然函数为:
![84b5ec8900e4d15c69cd2346c467347b](http://yizhanggou.top/imgs/2019/07/84b5ec8900e4d15c69cd2346c467347b.png)

取对数似然函数:
![6e988d575f022ff127411e4571c2aac9](http://yizhanggou.top/imgs/2019/07/6e988d575f022ff127411e4571c2aac9.png)

应用公式得：

![](http://yizhanggou.top/wp-content/uploads/2018/03/14033ad91e1a19a029dc7a2c1184e33e.png)

## 三、模型求解

随机梯度下降算法

![4c81f393a458ddbafad015e6334cb76e](http://yizhanggou.top/imgs/2019/07/4c81f393a458ddbafad015e6334cb76e.jpeg)

![992ec7e2515ea574ba2693ad33e0d9d1](http://yizhanggou.top/imgs/2019/07/992ec7e2515ea574ba2693ad33e0d9d1.png)

while not coverage：
![e803593ab6506ddcb031eb75f6658675](http://yizhanggou.top/imgs/2019/07/e803593ab6506ddcb031eb75f6658675.png)

![](http://yizhanggou.top/wp-content/uploads/2018/03/967c898cc2694a976d13992761780f4f-300x283.png)

对最大似然函数使用SGD下降算法

![728c7ed831b67ad21d235ed9cf3fd5c7](http://yizhanggou.top/imgs/2019/07/728c7ed831b67ad21d235ed9cf3fd5c7.png)

while not coverage:
对每个参数求偏导数

    - for sample x:#对于每个样本
    - for i in feature_list:#再对于每个参数

![](http://yizhanggou.top/wp-content/uploads/2018/03/d48841b6d26b1e5a2576ce589176d049.png)
本质上就是求偏导

第二种方法：最小二乘：

![](http://yizhanggou.top/wp-content/uploads/2018/03/201103052209144632.png)


## 四、总结

最大似然估计：主要能求出label出现的概率即可以考虑使用此目标函数

业界主要使用监督学习算法，研究和应用都是最广泛的，效果也非常好
