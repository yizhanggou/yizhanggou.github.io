---
title: "UserCF和ItemCF"
author: 一张狗
lastmod: 2019-07-06 09:24:33
date: 2018-07-16 17:15:59
tags: []
---

## 一、概念

- 基于人口统计学：建立用户profile 
    - 对于系统中每个用户有一个用户profile的建模，其中包括用户的基本信息，系统根据profile计算两个用户的相似度，找到用户的邻居，把邻居喜欢的物品推荐给用户。
    - ![](http://yizhanggou.top/imgs/2019/07/image005.jpg)
- 基于内容的推荐 
    - 对物品元数据进行建模，推荐与用户行为过的物品相似的物品。
    - ![](http://yizhanggou.top/imgs/2019/07/image007.jpg)
- 基于用户的**协同过滤**：通过历史数据发现相似用户 
    - 基于用户的协同过滤推荐机制和基于人口统计学的推荐机制都是计算用户的相似度，并基于“邻居”用户群计算推荐，但它们所不同的是如何计算用户的相似度，**基于人口统计学的机制只考虑用户本身的特征，而基于用户的协同过滤机制可是在用户的历史偏好的数据上计算用户的相似度**，它的基本假设是，喜欢类似物品的用户可能有相同或者相似的口味和偏好。
    - ![](http://yizhanggou.top/imgs/2019/07/image009.jpg)
- 基于项目的**协同过滤**：通过历史数据发现相似物品 
    - **基于项目的协同过滤推荐和基于内容的推荐其实都是基于物品相似度预测推荐，只是相似度计算的方法不一样**，前者是从用户历史的偏好推断，而后者是基于物品本身的属性特征信息。
    - ![](http://yizhanggou.top/imgs/2019/07/image011.jpg)
- 基于模型的协同过滤：基于模型的协同过滤推荐就是基于样本的用户喜好信息，训练一个推荐模型，然后根据实时的用户喜好的信息进行预测，计算推荐。


当已经对用户行为进行分析得到用户喜好后，我们可以根据用户喜好计算相似用户和物品，然后基于相似用户或者物品进行推荐，这就是最典型的 CF 的两个分支：基于用户的 CF 和基于物品的 CF。这两种方法都需要计算相似度，下面我们先看看最基本的几种计算相似度的方法。



## 二、计算相似度方法

欧几里德距离

最初用于计算欧几里德空间中两个点的距离，假设 x，y 是 n 维空间的两个点，它们之间的欧几里德距离是：

![](http://yizhanggou.top/imgs/2019/07/image003.gif)

可以看出，当 n=2 时，欧几里德距离就是平面上两个点的距离。

当用欧几里德距离表示相似度，一般采用以下公式进行转换：距离越小，相似度越大

![](http://yizhanggou.top/imgs/2019/07/image005.gif)

皮尔逊相关系数

皮尔逊相关系数一般用于计算两个定距变量间联系的紧密程度，它的取值在 [-1，+1] 之间。

![](http://yizhanggou.top/imgs/2019/07/image007.gif)

s<sub>x</sub>, s<sub>y</sub>是 x 和 y 的样品标准偏差。

两个变量之间的皮尔逊相关系数定义为两个变量之间的[协方差](https://zh.wikipedia.org/wiki/%E5%8D%8F%E6%96%B9%E5%B7%AE "协方差")和[标准差](https://zh.wikipedia.org/wiki/%E6%A0%87%E5%87%86%E5%B7%AE "标准差")的商：


![a04a49afb0df7b0fb38b8f1d8bcb8a2b](/imgs/2019/07/a04a49afb0df7b0fb38b8f1d8bcb8a2b.png)
Cosine 相似度

Cosine 相似度被广泛应用于计算文档数据的相似度：

![](http://yizhanggou.top/imgs/2019/07/image009.gif)

Tanimoto 系数

Tanimoto 系数也称为 Jaccard 系数，是 Cosine 相似度的扩展，也多用于计算文档数据的相似度：

![](http://yizhanggou.top/imgs/2019/07/image011.gif)

相似邻居的计算：

- k近邻：与该点最近的k个
- 基于相似度门槛的邻居：距离为 K 的区域中的所有点都作为当前点的邻居

三、计算推荐

UserCF

将一个用户对所有物品的偏好作为一个向量来计算用户之间的相似度。

![](http://yizhanggou.top/imgs/2019/07/image015.gif)

对于用户 A，根据用户的历史偏好，这里只计算得到一个邻居 – 用户 C，然后将用户 C 喜欢的物品 D 推荐给用户 A。

ItemCF

将所有用户对这个物品的偏好作为一个向量来计算物品之间的相似度。

![](http://yizhanggou.top/imgs/2019/07/image017.gif)

对于物品 A，根据所有用户的历史偏好，喜欢物品 A 的用户都喜欢物品 C，得出物品 A 和物品 C 比较相似，而用户 C 喜欢物品 A，那么可以推断出用户 C 可能也喜欢物品 C。


ItemCF vs UserCF

- 计算复杂度：当用户海量而物品数量固定时（比如一个在线网站）， Item CF 从性能和复杂度上比 User CF 更优。当物品海量更新频繁的时候（比如新闻，博客或者微内容的推荐系统），情况相反。
- 适用场景：UserCF适用于社交网站，ItemCF适用于非社交网络的网站中，内容内在的联系是很重要的推荐原则的网站。
- 推荐多样性和精度：UserCF倾向于推荐热门，ItemCF 的推荐有很好的新颖性，很擅长推荐长尾里的物品。两者结合的基本原则就是当采用 Item CF 导致系统对个人推荐的多样性不足时，我们通过加入 User CF 增加个人推荐的多样性，从而提高精度，而当因为采用 User CF 而使系统的整体多样性不足时，我们可以通过加入 Item CF 增加整体的多样性，同样同样可以提高推荐的精度。


UserCF

推荐与当前用户相似度高的N个用户产生过行为的物品，这些物品是当前用户没有行为过而其他N个用户行为过的物品的前M个。

余弦相似度改进：在分子中除了考虑两个用户共同行为的物品，还考虑到这个物品被多少个用户行为过。

|N(u)| 用户u行为过的物品总数

|N(v)| 用户v行为过的物品总数

|N(i)| i是u和v共同行为过的物品

![20150827162034378](http://yizhanggou.top/imgs/2019/07/20150827162034378.png)

加入时间因子：

- 相似度计算：用户u和用户v对物品i产生行为的时间越远，那么这两个用户的兴趣相似度就会越小。  
![201508271607312072](http://yizhanggou.top/imgs/2019/07/201508271607312072.png)
- 预测阶段：和当前用户相似的其他用户最近行为过得物品更容易得到推荐。  
![201508271607592573](http://yizhanggou.top/imgs/2019/07/201508271607592573.png)
优缺点：

- 群体/个体：更依赖于当前用户相近的用户群体的社会化行为
- 计算代价：适用于用户数较少的场合
- 适用场景：时效性强，用户个性化兴趣不太显著的场合
- 冷启动：新加入的物品能很快进入推荐列表
- 实时性：用户新的行为不一定导致推荐结果的变化


ItemCF

推荐和当前用户历史上行为过的物品相似的物品给当前用户；

对于当前用户历史行为过的每一个物品，推荐和每一个物品相似度高的前N个物品给当前用户；

余弦相似度改进：在分子中除了考虑这两个物品是否同时被用户行为过，还考虑该用户一共行为过的物品的数量。

i物品和j物品的相似度

![20150827162048588](http://yizhanggou.top/imgs/2019/07/20150827162048588.png)

相似度计算：在原先余弦相似度基础上，同一个用户对两个物品行为的时间距离越近，相似度越大。

![201508271609228872](http://yizhanggou.top/imgs/2019/07/201508271609228872.png)

物品相似度的归一化：将相似度矩阵按照最大值归一化，可以提高推荐的准确率，还可以提高推荐的覆盖率和多样性。

– 预测阶段：和当前时间距离近的用户作用过的物品相似的物品更容易得到推荐。

![20150827160933470](http://yizhanggou.top/imgs/2019/07/20150827160933470.png)

参考：
https://blog.csdn.net/xmu_jupiter/article/details/48029165
https://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy2/index.html


